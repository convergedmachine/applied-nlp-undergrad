{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contextualizes accuracy against a majority class baseline, and analyzes the most important features for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            # sample text is already tokenized; if yours is not, do so here\n",
    "            text=cols[1]\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the directory with your data (from the CheckData_TODO.ipynb exercise).  \n",
    "# The directory should contain train.tsv, dev.tsv and test.tsv\n",
    "directory=\"../data/text_classification_sample_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory)\n",
    "devX, devY=read_data(\"%s/dev.tsv\" % directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Implement the majority class baseline for your data that we went over in `Hyperparameters.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(trainY, devY):\n",
    "    # Find the most frequent label in the training data\n",
    "    label_counts = Counter(trainY)\n",
    "    majority_label = label_counts.most_common(1)[0][0]\n",
    "    \n",
    "    # Predict the majority label for all items in dev set\n",
    "    predictions = [majority_label] * len(devY)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct = sum(p == y for p, y in zip(predictions, devY))\n",
    "    accuracy = correct / len(devY)\n",
    "    \n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, a = majority_class(trainY,devY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: After experimenting with hyperparameter choices in class, what is the best accuracy that you uncovered on your development data?  Which hyperparameter choices led to that accuracy?  Plug in the values here and execute the cell to yield the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "Y_train=le.transform(trainY)\n",
    "Y_dev=le.transform(devY)\n",
    "\n",
    "# split the string on whitespace because we assume it has already been tokenized\n",
    "vectorizer = CountVectorizer(max_features=10000, analyzer=str.split, lowercase=False, strip_accents=None, binary=True)\n",
    "\n",
    "X_train = vectorizer.fit_transform(trainX)\n",
    "X_dev = vectorizer.transform(devX)\n",
    "logreg = linear_model.LogisticRegression(C=0.1, solver='lbfgs', penalty='l2')\n",
    "model=logreg.fit(X_train, Y_train)\n",
    "print(\"Accuracy: %.3f\" % logreg.score(X_dev, Y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: For binary classification using logistic regression, the parameters of the learned model are given in `model.coef_[0]`.  Print out the 25 features that are most associated with each class (i.e., the 25 parameters that have the largest positive values and the 25 parameters with largest negative values).  For reference, consider the `inverse_transform` function in [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder.transform) to get the class labels that correspond to positive(=1) and negative(=0), and the `vocabulary_` function in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to yield the index for each vocabulary term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_weights(learned_model, label_encoder, count_vectorizer):\n",
    "    # Get the learned coefficients for class 1 (positive class)\n",
    "    coefs = learned_model.coef_[0]\n",
    "    \n",
    "    # Get vocabulary mapping index -> feature\n",
    "    vocab = np.array([term for term, idx in sorted(count_vectorizer.vocabulary_.items(), key=lambda x: x[1])])\n",
    "    \n",
    "    # Identify the class labels (0 and 1)\n",
    "    class_labels = label_encoder.inverse_transform([0, 1])\n",
    "    \n",
    "    # Top 25 most positive (associated with class 1)\n",
    "    top_pos_idx = np.argsort(coefs)[-25:][::-1]  # largest positive weights\n",
    "    top_pos_terms = vocab[top_pos_idx]\n",
    "    \n",
    "    # Top 25 most negative (associated with class 0)\n",
    "    top_neg_idx = np.argsort(coefs)[:25]  # most negative weights\n",
    "    top_neg_terms = vocab[top_neg_idx]\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTop 25 features for class '{class_labels[1]}' (positive weights):\")\n",
    "    for term, weight in zip(top_pos_terms, coefs[top_pos_idx]):\n",
    "        print(f\"{term:20s} {weight:.4f}\")\n",
    "    \n",
    "    print(f\"\\nTop 25 features for class '{class_labels[0]}' (negative weights):\")\n",
    "    for term, weight in zip(top_neg_terms, coefs[top_neg_idx]):\n",
    "        print(f\"{term:20s} {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyze_weights(model, le, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:applied-machine-learning]",
   "language": "python",
   "name": "conda-env-applied-machine-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
